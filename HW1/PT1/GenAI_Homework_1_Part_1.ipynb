{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-l6TqdN7ZP"
      },
      "source": [
        "# GenAI Homework 1 Part 1 Vyacheslav Stepanyan\n",
        "\n",
        "#### Make sure that you read your API Key from a file and submit the api key file with your homework. Only TA and I will have access to your api key to check your homework. I will ask to delete api keys shared with us after checking the homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6fd4u4GNnud"
      },
      "source": [
        "**Task 1:** Create an AI assistant that will answer \"What's the temperature outside now\" or \"What's the temperature in Tokio now\" type of questions (location can be any big city). Ask for the location of the user if the location is not in the question. Use OpenAI APIs, [openweathermap](http://api.openweathermap.org/data/2.5/weather) API(it is free), and function calling.\n",
        "\n",
        "* Step 1: Use OpenAI Chat Completions API to get the location of the user if it is not given. If it is given, use function calling for getting weather api parameter(s).\n",
        "* Step 2: Call weather api for the given location.\n",
        "* Step 3: Call Chat Completions API again for processing the response of weather api. Make it to provide short answer like this: \"The temperature in Yerevan is -1.91 degrees Celsius\".\n",
        "* Step 4: Call Chat Completions API again to translate the output of Step 3 into Armenian.\n",
        "* Step 5: Use OpenAI Text to Speech API to create an audio version (mp3) of the output of Step 4.\n",
        "* Step 6: Use one of OpenAIs APIs to create an image based on the output of Step 3 (text to image).\n",
        "* Step 7: Use one of OpenAIs APIs to extract text (if any) from the output of Step 6\n",
        "* Step 8: Create a Chainlit app that will answer the questions mentioned at the beginning of the task and will output the outputs of Steps 3, 4, 5, 6, and 7.\n",
        "\n",
        "Useful links:\n",
        "* [Chainlit App Creation](https://docs.chainlit.io/get-started/pure-python])\n",
        "* [Text, Image, Audio and Video response with Chainlit](https://docs.chainlit.io/api-reference/elements/text)\n",
        "\n",
        "**Check a Chainlit app example at the end of this notebook.**\n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored  \n",
        "from openai import OpenAI\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('api_key.txt','r') as f:\n",
        "  openai.api_key = f.read()\n",
        "api_key = openai.api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if tools is not None:\n",
        "        json_data.update({\"tools\": tools})\n",
        "    if tool_choice is not None:\n",
        "        json_data.update({\"tool_choice\": tool_choice})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"function\": \"magenta\",\n",
        "    }\n",
        "    \n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"function\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"format\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"location\", \"format\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = []\n",
        "message = input('ask the question about weather :')\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": message})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools, tool_choice = 'auto'\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "while chat_response.json()[\"choices\"][0][\"finish_reason\"] != 'tool_calls': #assistant_message.content != None:  other option \n",
        "    message = input(assistant_message[\"content\"])\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "    chat_response = chat_completion_request(\n",
        "        messages, tools=tools, tool_choice = 'auto'\n",
        "    )\n",
        "    assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "    messages.append(assistant_message)\n",
        "else:\n",
        "    loc = assistant_message['tool_calls'][0]['function']['arguments'].split('\"')[3]\n",
        "    unit = assistant_message['tool_calls'][0]['function']['arguments'].split('\"')[7]\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
        "params = {\n",
        "    \"q\": loc,\n",
        "    \"APPID\": \"3128f76a7551a274746e884fd29a0e8f\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, params=params)\n",
        "info = {'location' : loc, 'temp' : response.json()['main']['temp'], 'unit' : unit}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'location': 'Yerevan', 'temp': 278.24, 'unit': 'celsius'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The temperature in Yerevan is 5.09 degrees Celsius.\n"
          ]
        }
      ],
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Provide a short description about the weather. Adjust the temperature unit from Kelvin to given unit, e.g The temperature in Yerevan is -1.91 degrees Celsius\"})\n",
        "messages.append({\"role\": \"user\", \"content\": f'{info['location']} , {info['temp']} Kelvin, {info['unit']}'})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=None, tool_choice = None\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "messages.append({\"role\": \"system\", \"content\": assistant_message})\n",
        "print(assistant_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Երևանի ջերմաստիճանը 5.09 աստիճան է Ցելսիուսով։\n"
          ]
        }
      ],
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"translate the your last response to armenian.\"}) #changed to gpt 4, as gpt3 couldn't handle this task\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=None, tool_choice = None, model = 'gpt-4-turbo-preview'\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "messages.append({\"role\": \"system\", \"content\": assistant_message})\n",
        "print(assistant_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Երևանի ջերմաստիճանը հինգ կոտորակ աստիճան է Ցելսիուսով։\n"
          ]
        }
      ],
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"change the numbers of your last message to words. e.g. Երևանում ջերմաստիճանը մինուս մեկ ու կես ցելսիուս է։\"}) #T2V can't generate armenian numbers from numbers in text\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=None, tool_choice = None,  model = 'gpt-4-turbo-preview' #changed to gpt 4, as gpt3 couldn't handle this task\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "messages.append({\"role\": \"system\", \"content\": assistant_message})\n",
        "print(assistant_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23360\\1839900914.py:9: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(\"եղանակ.mp3\")\n"
          ]
        }
      ],
      "source": [
        "api_key = openai.api_key\n",
        "client = OpenAI(api_key=api_key)\n",
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1-hd\",\n",
        "  voice=\"alloy\",\n",
        "  input=messages[-1]['content']\n",
        ")\n",
        "\n",
        "response.stream_to_file(\"եղանակ.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt= messages[2]['content'],\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"hd\",\n",
        "  n=1,\n",
        ")\n",
        "\n",
        "image_url = response.data[0].url\n",
        "image_url\n",
        "img_data = requests.get(image_url).content\n",
        "with open('weather_image.jpg', 'wb') as handler:\n",
        "    handler.write(img_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4⁰\n",
            "5.09\n",
            "Chily\n",
            "5.1⁰\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4-vision-preview\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"Is there text in the image? If yes what is it? DONT DESCRIBE THE IMAGE. OUTPUT ONLY TEXT THAT THERE IS ON IT\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": image_url,\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-02-11 23:28:17 - Your app is available at http://localhost:8000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 8000): only one usage of each socket address (protocol/network address/port) is normally permitted\n"
          ]
        }
      ],
      "source": [
        "!chainlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUW4_UbVqrZ"
      },
      "source": [
        "**Task 2:** Use a python library to download a short video from YouTube (e.g. https://github.com/pytube/pytube ), transcribe the text of the video with OpenAIs Whisper API, and use OpenAI's Moderation API to check it. Print the transcribed text and Moderation API response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wRomsBy3UnXl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribed Text:\n",
            "Alright, so here we are in front of the elephants. The cool thing about these guys is that they have really, really, really long trunks. And that's cool. And that's pretty much all there is to say.\n",
            "\n",
            "\n",
            "Moderation API Response:\n",
            "{'id': 'modr-8r9YdEKdal6N02Cpjuk5ZcHGkrAFU', 'model': 'text-moderation-007', 'results': [{'flagged': False, 'categories': {'sexual': False, 'hate': False, 'harassment': False, 'self-harm': False, 'sexual/minors': False, 'hate/threatening': False, 'violence/graphic': False, 'self-harm/intent': False, 'self-harm/instructions': False, 'harassment/threatening': False, 'violence': False}, 'category_scores': {'sexual': 0.0004069973365403712, 'hate': 0.0001445058878744021, 'harassment': 0.004312983714044094, 'self-harm': 6.655918127762561e-07, 'sexual/minors': 8.603204150858801e-06, 'hate/threatening': 4.2790756538124697e-07, 'violence/graphic': 0.0003304301353637129, 'self-harm/intent': 6.307342346190126e-07, 'self-harm/instructions': 3.646016921265982e-06, 'harassment/threatening': 3.7603549571940675e-06, 'violence': 7.529465074185282e-05}}]}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import requests\n",
        "from pytube import YouTube\n",
        "from openai import OpenAI\n",
        "\n",
        "with open('api_key.txt','r') as f:\n",
        "  openai.api_key = f.read()\n",
        "\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "OPENAI_API_KEY = openai.api_key\n",
        "\n",
        "\n",
        "def download_video(url, output_path):\n",
        "    # Download a short video from YouTube\n",
        "    yt = YouTube(url)\n",
        "    ys = yt.streams.first()\n",
        "    ys.download(output_path)\n",
        "\n",
        "def transcribe_video(video_path):\n",
        "    # Use OpenAI's Whisper API to transcribe the video\n",
        "    audio_file = open(video_path, \"rb\")\n",
        "    transcript = client.audio.transcriptions.create(\n",
        "    model=\"whisper-1\", \n",
        "    file=audio_file, \n",
        "    response_format=\"text\"\n",
        "    )\n",
        "    \n",
        "    return transcript\n",
        "\n",
        "def moderation_check(text):\n",
        "    # Use OpenAI's Moderation API to check the transcribed text\n",
        "    url = \"https://api.openai.com/v1/moderations\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f'Bearer {OPENAI_API_KEY}' \n",
        "    }\n",
        "    data = {\n",
        "        \"input\": text\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "    return response.json()\n",
        "\n",
        "youtube_url = \"https://youtu.be/jNQXAC9IVRw?si=hwO-jjLC9Vta1s7g\" \n",
        "output_path = \"./downloaded_video\"\n",
        "\n",
        "# Step 1: Download video from YouTube\n",
        "download_video(youtube_url, output_path)\n",
        "\n",
        "# Step 2: Transcribe the video using OpenAI Whisper API\n",
        "transcribed_text = transcribe_video(output_path + \"/\" + os.listdir(output_path)[0])\n",
        "\n",
        "# # Step 3: Check the transcribed text using OpenAI Moderation API\n",
        "moderation_response = moderation_check(transcribed_text)\n",
        "\n",
        "# Step 4: Print the results\n",
        "print(f\"Transcribed Text:\\n{transcribed_text}\\n\")\n",
        "print(f\"Moderation API Response:\\n{moderation_response}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJGFkzMldY0p"
      },
      "source": [
        "# END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GenAI_venv",
      "language": "python",
      "name": "genai_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
