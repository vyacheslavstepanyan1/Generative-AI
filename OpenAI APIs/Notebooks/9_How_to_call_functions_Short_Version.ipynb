{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e67f200",
      "metadata": {
        "id": "3e67f200"
      },
      "source": [
        "# How to call functions with chat models\n",
        "\n",
        "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
        "\n",
        "`tools` is an optional parameter in the Chat Completion API which can be used to provide function specifications. The purpose of this is to enable models to generate function arguments which adhere to the provided specifications. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
        "\n",
        "Within the `tools` parameter, if the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can be forced to use a specific function by setting the `tool_choice` parameter to `{\"name\": \"<insert-function-name>\"}`. The API can also be forced to not use any function by setting the `tool_choice` parameter to `\"none\"`. If a function is used, the output will contain `\"finish_reason\": \"function_call\"` in the response, as well as a `tool_choice` object that has the name of the function and the generated function arguments.\n",
        "\n",
        "### Overview\n",
        "\n",
        "This notebook contains the following 2 sections:\n",
        "\n",
        "- **How to generate function arguments:** Specify a set of functions and use the API to generate function arguments.\n",
        "- **How to call functions with model generated arguments:** Close the loop by actually executing functions with model generated arguments."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c85e26",
      "metadata": {
        "id": "64c85e26"
      },
      "source": [
        "## How to generate function arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e71f33",
      "metadata": {
        "id": "80e71f33",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install scipy\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "!pip install termcolor\n",
        "!pip install openai\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dab872c5",
      "metadata": {
        "id": "dab872c5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import requests\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo-0613\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "clTYSliMhnWq",
      "metadata": {
        "id": "clTYSliMhnWq"
      },
      "outputs": [],
      "source": [
        "with open('C:\\\\Users\\\\User\\\\Desktop\\\\AUA\\\\Generative AI\\\\HW1\\\\api_key.txt','r') as f:\n",
        "  openai.api_key = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ee6a93",
      "metadata": {
        "id": "69ee6a93"
      },
      "source": [
        "### Utilities\n",
        "\n",
        "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "745ceec5",
      "metadata": {
        "id": "745ceec5"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if tools is not None:\n",
        "        json_data.update({\"tools\": tools})\n",
        "    if tool_choice is not None:\n",
        "        json_data.update({\"tool_choice\": tool_choice})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29d4e02b",
      "metadata": {
        "id": "29d4e02b"
      },
      "source": [
        "### Basic concepts\n",
        "\n",
        "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d2e25069",
      "metadata": {
        "id": "d2e25069"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"location\", \"format\"],\n",
        "            },\n",
        "        }\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc39899",
      "metadata": {
        "id": "bfc39899"
      },
      "source": [
        "If we prompt the model about the current weather, it will respond with some clarifying questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "518d6827",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "518d6827",
        "outputId": "294ad54c-2d4e-4f2c-a41d-ad405005366d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': \"Sure, may I know the location for which you'd like to know the weather?\"}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
        "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "893fd8c9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-8qm3AayJgioyyRudu8X0B6DBRxyX9',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1707588452,\n",
              " 'model': 'gpt-3.5-turbo-0613',\n",
              " 'choices': [{'index': 0,\n",
              "   'message': {'role': 'assistant',\n",
              "    'content': None,\n",
              "    'tool_calls': [{'id': 'call_sGlYcSzjqjz2Fue6bGO9KMgh',\n",
              "      'type': 'function',\n",
              "      'function': {'name': 'get_current_weather',\n",
              "       'arguments': '{\\n  \"location\": \"Yerevan, Armenia\"\\n}'}}]},\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'tool_calls'}],\n",
              " 'usage': {'prompt_tokens': 121, 'completion_tokens': 20, 'total_tokens': 141},\n",
              " 'system_fingerprint': None}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "66f31fc6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(chat_response.json())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c999375",
      "metadata": {
        "id": "4c999375"
      },
      "source": [
        "Once we provide the missing information, it will generate the appropriate function arguments for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "23c42a6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23c42a6e",
        "outputId": "b55fe849-482e-4348-ad5b-d04909097ec8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'role': 'assistant',\n",
              " 'content': None,\n",
              " 'tool_calls': [{'id': 'call_sGlYcSzjqjz2Fue6bGO9KMgh',\n",
              "   'type': 'function',\n",
              "   'function': {'name': 'get_current_weather',\n",
              "    'arguments': '{\\n  \"location\": \"Yerevan, Armenia\"\\n}'}}]}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages.append({\"role\": \"user\", \"content\": \"I'm in Yerevan, Armenia.\"})\n",
        "chat_response = chat_completion_request(\n",
        "    messages, tools=tools\n",
        ")\n",
        "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
        "messages.append(assistant_message)\n",
        "assistant_message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7XWMFogNX92b",
      "metadata": {
        "id": "7XWMFogNX92b"
      },
      "outputs": [],
      "source": [
        "loc = assistant_message['tool_calls'][0]['function']['arguments'].split('\"')[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "845f6c28",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yerevan, Armenia'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "Q3q698czoMgO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3q698czoMgO",
        "outputId": "a944ab57-e9c8-4aff-d5a3-85f5c1c52c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "{'coord': {'lon': 44.5136, 'lat': 40.1811}, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': 277.24, 'feels_like': 277.24, 'temp_min': 277.24, 'temp_max': 277.24, 'pressure': 1023, 'humidity': 65}, 'visibility': 10000, 'wind': {'speed': 0, 'deg': 0}, 'clouds': {'all': 6}, 'dt': 1707585900, 'sys': {'type': 1, 'id': 8851, 'country': 'AM', 'sunrise': 1707537741, 'sunset': 1707575406}, 'timezone': 14400, 'id': 616052, 'name': 'Yerevan', 'cod': 200}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
        "params = {\n",
        "    \"q\": loc,\n",
        "    \"APPID\": \"3128f76a7551a274746e884fd29a0e8f\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "print(response.status_code)  # Prints the status code of the response\n",
        "print(response.json())  # Prints the JSON content of the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c17d9906",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(response.json())\n",
        "# print(response.json()['main']['temp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "TPVCphytejHp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "TPVCphytejHp",
        "outputId": "4ed4a44b-eaaa-44bb-b970-24867e080f3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"coord\":{\"lon\":44.5136,\"lat\":40.1811},\"weather\":[{\"id\":800,\"main\":\"Clear\",\"description\":\"clear sky\",\"icon\":\"01n\"}],\"base\":\"stations\",\"main\":{\"temp\":277.24,\"feels_like\":277.24,\"temp_min\":277.24,\"temp_max\":277.24,\"pressure\":1023,\"humidity\":65},\"visibility\":10000,\"wind\":{\"speed\":0,\"deg\":0},\"clouds\":{\"all\":6},\"dt\":1707585900,\"sys\":{\"type\":1,\"id\":8851,\"country\":\"AM\",\"sunrise\":1707537741,\"sunset\":1707575406},\"timezone\":14400,\"id\":616052,\"name\":\"Yerevan\",\"cod\":200}'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "UywtSfchf4DE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UywtSfchf4DE",
        "outputId": "06293e52-30f4-40f0-9ea2-1b0fec782cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The temperature in Yerevan is 277.24 Kelvin. To convert it to Celsius, you subtract 273.15 from the Kelvin temperature. \n",
            "\n",
            "277.24 K - 273.15 = 4.09Â°C\n",
            "\n",
            "So the temperature in Yerevan is approximately 4.09 degrees Celsius.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4-1106-preview\",\n",
        "  response_format={ \"type\": \"text\" },\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are weather assistant\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{response.text} based on this information what the temerature in celcius in the given location. Provide short answer.\"}\n",
        "  ]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GxiAx6JaBoBI",
      "metadata": {
        "id": "GxiAx6JaBoBI"
      },
      "source": [
        "# END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GenAI_venv",
      "language": "python",
      "name": "genai_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
