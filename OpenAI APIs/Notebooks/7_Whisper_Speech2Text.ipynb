{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "NS51LDCQVlpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"Charents.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGJQnTyJxLpU",
        "outputId": "d0496a80-e780-4690-f5a4-30731aa76cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 59.8MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " holidayарaning'�� arbets прос rator Úhna m'ya kagak neri hazaramya karnamsirum. Úr elinem, čem morana esvokbazain yer kerimer. čem morana agot kdartsat yerkatagir gyr kerimer. İnčkán el sursir t'es khotsen arjunakam ver kerimer. Eli esvorku arnavarim hayastan, yarnamsirum. İmkarotat srtihamar votmi uris hekiatčka. Narek atzu, kuchaki peslu sapsak cakatčka. Aškhar hantir araratineman germak gagatčka. İnčkán haz parki jampa esim massi srtam sirum.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/openai/whisper"
      ],
      "metadata": {
        "id": "2VzjikPA00Hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"output.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "1PJhrUwOWWbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ad57c6-cade-47e6-df5b-e18fa6c1f6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Today is a wonderful day to build something people love.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7cbqIj2z9En"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}